{"componentChunkName":"component---src-templates-page-tsx","path":"/chant/","result":{"data":{"markdownRemark":{"html":"<p>この解説記事では、総務省の公開する PDF ファイルを CSV ファイルに変換し、データとして活用しやすい形に変えるまでの過程を紹介します。</p>\n<h2>はじめに：なぜ PDF ではいけないのか</h2>\n<p>このサイトでは、総務省が<a href=\"https://www.soumu.go.jp/kojinbango_card/\">「マイナンバーカード交付状況について」</a>として公開している PDF ファイルを <a href=\"/data\">CSV ファイルに変換して提供</a>しています。\nPDF から CSV に自動で変換できるのならば、PDF のままでもよいのではないか？と思う方もいらっしゃるかもしれません。\nしかし、そのためには、本来必要がない多くの処理が必要となっているのです。</p>\n<p>当該 PDF で公開されているのは主に「<strong>表形式</strong>」のファイルで、団体区分別の交付率、区分別交付率上位 10 位、都道府県の交付率一覧、男女・年齢別の集計、市区町村の交付率一覧の表が公開されています。</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 400px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75.43859649122807%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAADIElEQVQ4y11Ta2/aSBT1///YbbVa9UOrflhptVXVV0JCkuLYNDgYzMtPjPGb8GgCwdjgEHJ6Z6pGqx3papjjc8/cO/cgVIMF3ms2Km6KjwMPH3ou3tYUvPx0ildfzvDn1wu8+HDMz6+rMt5JKj4ZAd7JLbz6fIa/KiJ9q+KPjyeohj8grDYFeqaNPkU4mWJT7rHeljwyipzO2XaHdbHDfb7FapNzfFM+EGf3zPvNFTpOikpjiH9PFJwqDuR+AqkXQ9QCvD9p4Lhu4LIbcfz0ysKbfyr4ctnjWLVh40ge4Fju8/x624GwXK1R7g8YeT4m0wVyuumOsDVVPpnOoXX7cNzxMzadLWA5LmEelvcZj/ssRxAlhI0g5JsNtkUOfTBAp6MhyzKUux0eH/coyxKWZcI0DM45HB6x3z/AMHTYlsU57Aw8YT6fYTQiwfV6jSRJiGTwCMMQRbElIr0liTPMNE1s6GKGFUXBz0PX5ReyYPjt3R3GY/+XICOn6YQiBTsvVyueyHDf93kU2y12VDnbozhGFMXY0m/GY/hyueT5wmp5B1MfwBu5SOMIkzRBQvv+ocR/1yZb40AtPlHbz+vpgP8voWWG+PuzhDPFhtQZo94LUFOHOL7soNZycd7QobsxTXKAs4aJtruA3PXxTXVwNYhwJGo4V0zKt3BNHhYsL0VV1tAckFjLwNfz72j2RziiXWrquKi3yacjyC0LFVFF7VqHZoX43rYgqQauuw6+XXVwXtcgKx0IkzSGJNYQhwGy+xV6NGnqDcHYo9ZDBL7Hn0FrNXFZu0Bbbf6a6vQGoT/mbfreCJMkwtCxIcT0wI1Gg0bu4cftLdrtNg0mg+MMaWpjjrMBNJsqFEVBt9fjLkiSFJ43psHsuF3CkASH1PJ0OoWmaWDCi8WC24R5kZEYxiYcRRF5tINutwvbtvn0b+lyhjPbMB6zG/fhzc0NVFXlifP5HP1+nye45DNGYlWynYm11BZ03UCe52B5QRBwyzAOswwX9DwPYk2kykzMZjPePvOi4zi8Gov+EUxcliSIosi/r8inTIQZnHXDimA6rLufoMA3wsyMuIMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"データサンプル\"\n        title=\"データサンプル\"\n        src=\"/static/cad7c0657c5b92a2171f6cbfb94cef8d/6a8a8/page-1.png\"\n        srcset=\"/static/cad7c0657c5b92a2171f6cbfb94cef8d/5459c/page-1.png 285w,\n/static/cad7c0657c5b92a2171f6cbfb94cef8d/6a8a8/page-1.png 400w\"\n        sizes=\"(max-width: 400px) 100vw, 400px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">データサンプル</figcaption>\n  </figure></p>\n<p>これらをグラフではなく表敬式で公開するということは、利用用途として「データとして活用してもらう」ために行っていると思って良いでしょう。\n特に後半の市区町村別のリストなどは、そのまま眺めていてもあまり意味がありません。\nデータとして活用してもらうのであれば、EXCEL 等のファイルをそのまま掲載するべきです。PDF を作る前に EXCEL などのツールで集計していることは想像に難くありませんので、ぜひそのファイルを公開してほしいものです。</p>\n<p>生成された PDF から、もともとあったであろうデータを取り出すことは、しばしば「<strong>餅から米を作る</strong>」とも表現されます。今回はプログラムで CSV 化を行っていますが、プログラムを介さずに PDF からコピーペーストで市区町村のデータを作ろうとすると、PDF から EXCEL に 32 回のコピーペーストを行い、更に”,“や”%“を削ったりして文字型から数値型に変換する必要があります。この作業を、記事執筆現在公開されている 17 ファイル分行ってもらうことを、政府担当者は想定しているのでしょうか。気が遠くなる作業です。</p>\n<p>ぜひ、元の EXCEL を公開いただきたいと思います。本記事を読んだ政府担当者の方は、ぜひこのサイトをご担当者にご紹介ください。</p>\n<h2>PDF から CSV 変換に必要だった処理（供養の過程）</h2>\n<p>前置きが長くなってしまいましたが、供養のプロセスを紹介していきます。ソースコードにリンクしていますが、2020 年 7 月 25 日 時点のものなので、今後ソースコードの修正で行数がずれる可能性がありますのでご了承ください。</p>\n<h3>1. PDF から CSV ファイルを作る</h3>\n<p>まず、PDF から表組データを \b 取ってくる<a href=\"https://camelot-py.readthedocs.io/en/master/\">camelot</a>というライブラリを使ってデータを CSV で保存しています。\n<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/download.py#L29\">GitHub の該当処理</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tables <span class=\"token operator\">=</span> camelot<span class=\"token punctuation\">.</span>read_pdf<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> pages<span class=\"token operator\">=</span><span class=\"token string\">\"all\"</span><span class=\"token punctuation\">,</span> line_scale<span class=\"token operator\">=</span><span class=\"token number\">40</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>しかし、表によっては<code class=\"language-text\">camelot</code>がうまくパースできず、スペースでつながったデータができてしまい、代わりに隣列が空白になってしまうなどの不具合がありました。\n<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/stringutil.py#L105\">100 行近くのスクリプト</a>を書いて、誤変換を発見し修正しています。</p>\n<h3>2. カンマや%を取り除いて文字列を数字データに変換する</h3>\n<p>3 桁区切りの数字は、人間には読みやすいですがコンピューターには数字として認識されません。したがって、数値型であるべきフィールドは、<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/stringutil.py#L60\">”,“や”%“を取り除いて数字型に変換しています。</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber 0\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">','</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'-'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'%'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'％'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>isnumeric<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'.'</span> <span class=\"token keyword\">in</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">','</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'%'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n                             <span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'％'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">','</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'%'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n                           <span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'％'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">return</span> text</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<h3>3. 文字コードがおかしいデータを修正する</h3>\n<p>こちらについては以前 Qiita の記事<a href=\"https://qiita.com/hal_sk/items/8a95e9daa17b500f3f27\">[BOD 供養寺] スクレイピングしてきたデータの文字コードがおかしかったので修正した</a>でも書いたのですが、「埼玉」等の文字の文字コードが平成 29 年 3 月 8 日時点分だけ他の PDF と違っていました。見た目は全く同じですが、このままだと BI ツール等からは違うデータとして扱われてしまいます。\nしたがって、<code class=\"language-text\">unicodedata.normalize</code> で正規化を行いました。また、「亀」や「戸」といった文字もコードが違っていましたので、<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/converter.py#L26\">合わせて修正しています</a>。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">normalizechar</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># if this text is inside of Kangxi Radicals block, it should be normalized.</span>\n    <span class=\"token comment\"># see https://en.wikipedia.org/wiki/Kangxi_radical#:~:text=They%20are%20officially%20part%20of,the%20%22CJK%20Radicals%20Supplement%22.  # noqa: E501</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>c <span class=\"token operator\">>=</span> <span class=\"token string\">b'\\xe2\\xbc\\x80'</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">and</span>\n            c <span class=\"token operator\">&lt;=</span> <span class=\"token string\">b'\\xe2\\xbf\\x95'</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># '⼀'から'⿕' の範囲</span>\n        <span class=\"token keyword\">return</span> unicodedata<span class=\"token punctuation\">.</span>normalize<span class=\"token punctuation\">(</span><span class=\"token string\">'NFKC'</span><span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> c\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">normalize</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># see this: https://en.wikipedia.org/wiki/CJK_Radicals_Supplement</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        ret <span class=\"token operator\">=</span> <span class=\"token string\">''</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>normalizechar<span class=\"token punctuation\">,</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># blow strings also should be fixed. https://ja.wiktionary.org/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:Unicode_CJK_Radicals_Supplement   # noqa: E501</span>\n        table <span class=\"token operator\">=</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>maketrans<span class=\"token punctuation\">(</span><span class=\"token string\">\"⺟⺠⻁⻄⻑⻘⻝⻤⻨⻩⻫⻭⻯⻲戶黑\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"母民虎西長青食鬼麦黄斉歯竜亀戸黒\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> ret<span class=\"token punctuation\">.</span>translate<span class=\"token punctuation\">(</span>table<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> s</code></pre></div>\n<h3>4. 分かれている CSV ファイルを一つのファイルにつなげる</h3>\n<p>PDF から <code class=\"language-text\">camelot</code> で CSV を抽出した場合、改ページなどの影響により同じ表でも複数のファイルに分かれてしまいます。ヘッダの文字列からデータの種類を把握して、同じ内容のデータは一つのファイルにまとめています。</p>\n<h3>5. 日付のデータを追加する</h3>\n<p>テーブルの中には算出日の情報が含まれていないので、そのままだと複数の CSV ファイルを纏めて取り込んだときに、いつのデータかわからなくなってしまいます。ファイル名「マイナンバーカード交付状況（平成 YY 年 M 月 D 日時点）」の部分から日付を取得して、列として追加しています。その際、和暦の表記を日付型に変換するため、<a href=\"https://pypi.org/project/Japanera/\">Japanera</a>というライブラリを使っています。ただし、フォーマットの問題で一度の関数では変換することができず、<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/stringutil.py#L36\">一度正規表現で年月日を取り出し、再度 Japanera にかけるなどの処理を行っています</a>。</p>\n<h3>6. 人口や交付件数の算出基準日を列として追加する</h3>\n<p>人口及び交付枚数は、下記のようにテーブルのヘッダに算出基準日が記載されています。ただし、これを BI ツール等から読み込もうとしても違う列と判断されてしまいますし、基準日という重要な情報がカラム名に入ってしまいます。したがって、<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/stringutil.py#L8\">ヘッダの文字列から日付を抜き出し、列として追加しています。</a></p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 690px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.6140350877193%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAABM0lEQVQY002MS0/CUBCF+8dds3KlCxFDXBkF0QBCUAyCYoEWWgpItQiEd5HKM7hw83m9auLi5Jwz880o78sNb8sti+0n3uqDibdkOt9Iue9r4WvGswXun4vZNzN0vd+++sevULTWGxH1lcPLHOF7m6Q5krpteiQqffwXWfZPb6T7/GcE4yoH5xl2do9kj+k90k8zUtaEmNZFKTgzTnIv+AIRAlclopURiapLKO+wF8qIPBW5RdwYE0zqHF+bJKyp3McFexhVCT+2SVo/nNIezrAHc7JlG8MZUu+4FBsd8sYzyWyRB9NBtRw5Sz8aPBi2zLlyk0JdPLorCOYF3e5hintls14xGfVJ36TodTss5h61qoFR1qnoGmr+nudmQ3SNslai2ahhVnSZtaIqvW6ZUuPhgC++nVcIRD6ZQgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"日付入りのデータ\"\n        title=\"日付入りのデータ\"\n        src=\"/static/68daf8fcb1647a7c0fd6f9ac9951aee0/86e67/cells.png\"\n        srcset=\"/static/68daf8fcb1647a7c0fd6f9ac9951aee0/5459c/cells.png 285w,\n/static/68daf8fcb1647a7c0fd6f9ac9951aee0/2cee3/cells.png 570w,\n/static/68daf8fcb1647a7c0fd6f9ac9951aee0/86e67/cells.png 690w\"\n        sizes=\"(max-width: 690px) 100vw, 690px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">日付入りのデータ</figcaption>\n  </figure>{width=50 height=50}</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">extract_date_from_header</span><span class=\"token punctuation\">(</span>header<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> datetime<span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"'人口（H28.1.1時点）' といったテキストから日付を取得\n    Args:\n        header (str): '人口（H28.1.1時点）' といったテキスト\n    Returns:\n        datetime: 取得した日付\n    \"\"\"</span></code></pre></div>\n<p>ちなみに、<a href=\"https://www.soumu.go.jp/main_content/000620269.pdf\">平成 31 年 4 月 1 日のデータ</a>には<code class=\"language-text\">【H31.41時点】</code>という間違った日付が入っており、<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/commit/151f8aee9136adacde8a0e638b8787e31760467d\">データ列に不自然な空きがある場合には前後のデータで埋める</a>という処理も加えています。</p>\n<h3>7. セル結合されたデータを修正する</h3>\n<p>男女・年齢別の表は前項の図のようにヘッダが 2 行になっており、さらにセル結合がされているので、そのままでは読み込みづらいデータとなってしまいます。したがって、<strong>男、女、計</strong>となっているヘッダを<strong>人口（男）、人口（女）、人口（計）</strong>という形に<a href=\"https://github.com/codeforjapan/mynumbercard_statistics/blob/5c39063cad09eaae3e3bafa94d9de651a74f809f/converter.py#L228\">変換しています</a>。</p>\n<p>また、団体区分別のデータもセル結合されていたので一つにまとめています。</p>\n<h2>PDF はデータ公開に向かない</h2>\n<p>以上が供養手順です。様々な落とし穴がありましたが、無事に綺麗な CSV ファイルが提供できるようになりました。\n最初から CSV や EXCEL で公開されていれば、セル結合や日付の列追加以外の処理は本来必要が無かったはずの作業です。\n都道府県コードや市区町村コードを追記していれば更に良いデータになったと思います。</p>\n<p><a href=\"/aboutdata/\">データ形式について</a> に、完成後の CSV ファイルのフォーマットがありますので、参考にしていただければ幸いです。</p>\n<p>Code for Japan には、筆者の関も含め、<a href=\"https://cio.go.jp/policy-opendata#dendoushi\">内閣官房のオープンデータ伝道師</a>が多数在籍しています。本件に限らず、オープンデータ化を検討して/悩んでいる行政担当者がおられましたら、ぜひお気軽にご相談ください。info@code4japan.org 宛にメールいただければと思います。</p>","excerpt":"この解説記事では、総務省の公開する PDF ファイルを CSV ファイルに変換し、データとして活用しやすい形に変えるまでの過程を紹介します。 はじめに：なぜ PDF ではいけないのか このサイトでは、総務省が「マイナンバーカード交付状況について」として公開している PDF…","frontmatter":{"title":"BADオープンデータの供養の過程"}}},"pageContext":{"slug":"/chant/"}}}